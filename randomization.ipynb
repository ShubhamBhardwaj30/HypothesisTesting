{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9d10b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72911b5",
   "metadata": {},
   "source": [
    "## üîπ 1. Simple Randomization (Coin Flip)\n",
    "\n",
    "- Each unit (user/cluster) is independently randomized.\n",
    "    * May result in imbalance (e.g., 7 treatment, 3 control).\n",
    "\t* Fine when large samples are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "990b2f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 0 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_clusters = 10\n",
    "assignment = np.random.choice([0, 1], size=n_clusters)\n",
    "print(assignment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d01521",
   "metadata": {},
   "source": [
    "## üîπ 2. Complete Randomization (Fixed Split)\n",
    "\n",
    "- Ensure exact balance between groups.\n",
    "- Guarantees equal treatment/control sizes (5 and 5 here).\n",
    "- Common in A/B tests to avoid imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0473e1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "n_clusters = 5\n",
    "half = n_clusters // 2\n",
    "\n",
    "# Randomly decide which label gets the extra cluster\n",
    "labels = [0, 1]\n",
    "np.random.shuffle(labels)  # randomize label order\n",
    "\n",
    "assignment = np.array([labels[0]]*half + [labels[1]]*(n_clusters - half))\n",
    "np.random.shuffle(assignment)  # shuffle to randomize cluster assignment\n",
    "print(assignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aafdf69",
   "metadata": {},
   "source": [
    "## üîπ 3. Blocked Randomization\n",
    "\n",
    "Randomize within small blocks to maintain balance over time or within subgroups.\n",
    "- Every 4 clusters ‚Üí 2 control, 2 treatment.\n",
    "- Prevents imbalance if experiment stops early.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66df89e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(0)]\n"
     ]
    }
   ],
   "source": [
    "n_clusters = 12\n",
    "block_size = 4   # each block has 2 control, 2 treatment\n",
    "assignment = []\n",
    "\n",
    "for _ in range(n_clusters // block_size):\n",
    "    block = np.array([0] * (block_size//2) + [1] * (block_size//2))\n",
    "    np.random.shuffle(block)\n",
    "    assignment.extend(block)\n",
    "\n",
    "print(assignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb739e72",
   "metadata": {},
   "source": [
    "## üîπ 4. Stratified Randomization\n",
    "\n",
    "First divide clusters into strata (based on covariates), then randomize within each stratum.\n",
    "\n",
    "Example: Stratify clusters into ‚Äúsmall‚Äù vs ‚Äúlarge‚Äù based on size.\n",
    "- Ensures treatment/control are balanced within strata.\n",
    "- Useful if cluster size (or baseline metric) strongly influences outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cae75e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cluster  size stratum  treatment\n",
      "0        0    88   large          1\n",
      "1        1    78   large          0\n",
      "2        2    64   small          0\n",
      "3        3    92   large          1\n",
      "4        4    57   small          0\n",
      "5        5    70   small          1\n",
      "6        6    88   large          1\n",
      "7        7    68   small          0\n",
      "8        8    72   small          1\n",
      "9        9    60   small          0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "cluster_sizes = np.random.randint(50, 100, size=10)  # cluster sizes\n",
    "\n",
    "df = pd.DataFrame({\"cluster\": range(10), \"size\": cluster_sizes})\n",
    "\n",
    "df[\"stratum\"] = np.where(df[\"size\"] < 75, \"small\", \"large\")\n",
    "\n",
    "assignments = []\n",
    "for stratum, group in df.groupby(\"stratum\"):\n",
    "    n = len(group)\n",
    "    assign = np.array([0]*(n//2) + [1]*(n - n//2))\n",
    "    np.random.shuffle(assign)\n",
    "    assignments.extend(assign)\n",
    "\n",
    "df[\"treatment\"] = assignments\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da700ca",
   "metadata": {},
   "source": [
    "## üîπ 5. Re-Randomization / Constrained Randomization\n",
    "\n",
    "### Simple re-randomization of the cluster-sizes\n",
    "Randomize, then check balance on covariates. If imbalance is too high, randomize again.\n",
    "- Guarantees covariate balance.\n",
    "- Used in constrained randomization designs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fc753e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster sizes: [88 78 64 92 57 70 88 68 72 60]\n",
      "Assignment: [1 1 1 0 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "def randomize_until_balanced(cluster_sizes, threshold=5):\n",
    "    n = len(cluster_sizes)\n",
    "    while True:\n",
    "        assignment = np.random.choice([0, 1], size=n)\n",
    "        mean_diff = abs(cluster_sizes[assignment==1].mean() -\n",
    "                        cluster_sizes[assignment==0].mean())\n",
    "        if mean_diff < threshold:  # accept only if balanced\n",
    "            return assignment\n",
    "\n",
    "np.random.seed(42)\n",
    "sizes = np.random.randint(50, 100, size=10)\n",
    "assign = randomize_until_balanced(sizes, threshold=3)\n",
    "print(\"Cluster sizes:\", sizes)\n",
    "print(\"Assignment:\", assign)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6df46bf",
   "metadata": {},
   "source": [
    "### Multi-variate re-rendomization\n",
    "üß† 1Ô∏è‚É£ What it is\n",
    "\n",
    "In single-covariate rerandomization (like your code), you only check one balance condition:\n",
    "\n",
    "|mean(cluster size in treatment) ‚àí mean(cluster size in control)| ‚â§ threshold\n",
    "\n",
    "But in real experiments, you often have several baseline covariates to balance:\n",
    "- cluster size\n",
    "- baseline engagement rate\n",
    "- region\n",
    "- average income\n",
    "- etc.\n",
    "\n",
    "You want all of them to be ‚Äúwell balanced‚Äù between treatment and control.\n",
    "\n",
    "So you extend the rerandomization criterion to a vector of covariates.\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "‚öôÔ∏è 2Ô∏è‚É£ How it‚Äôs done: the Mahalanobis distance approach\n",
    "\n",
    "You compute a single multivariate balance metric that summarizes how different the two groups are across all covariates simultaneously.\n",
    "\n",
    "That metric is the Mahalanobis distance between the treatment and control covariate means:\n",
    "\n",
    "M = (\\bar{x}_T - \\bar{x}_C)‚Äô \\Sigma^{-1} (\\bar{x}_T - \\bar{x}_C)\n",
    "\n",
    "where\n",
    "- \\bar{x}_T, \\bar{x}_C = vectors of mean covariate values in treatment and control\n",
    "- \\Sigma = covariance matrix of covariates across all units\n",
    "\n",
    "Then you:\n",
    "1.\tRandomize assignments.\n",
    "2.\tCompute M.\n",
    "3.\tIf M < \\text{threshold}, accept; otherwise, rerandomize.\n",
    "\n",
    "This ensures overall covariate balance across all dimensions, not just one.\n",
    "\n",
    "‚∏ª\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "377f0866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accepted assignment with Mahalanobis distance: 0.2479\n",
      "treatment              0          1  abs_diff\n",
      "cluster_size   72.826087  75.129630  2.303543\n",
      "baseline_rate   0.096849   0.099722  0.002872\n",
      "region_EU       0.326087   0.277778  0.048309\n",
      "region_NA       0.391304   0.351852  0.039452\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# --------------------------\n",
    "# Step 1: Define Mahalanobis distance\n",
    "# --------------------------\n",
    "def mahalanobis_distance(df_treat, df_ctrl, covariate_cols):\n",
    "    # Convert covariates to numeric arrays\n",
    "    x_t = df_treat[covariate_cols].astype(float).to_numpy()\n",
    "    x_c = df_ctrl[covariate_cols].astype(float).to_numpy()\n",
    "    \n",
    "    # Mean vectors\n",
    "    mean_t = x_t.mean(axis=0)\n",
    "    mean_c = x_c.mean(axis=0)\n",
    "    \n",
    "    # Combine treatment + control for covariance estimation\n",
    "    combined = np.vstack([x_t, x_c])\n",
    "    cov = np.cov(combined, rowvar=False)\n",
    "    inv_cov = np.linalg.inv(cov)\n",
    "    \n",
    "    # Use SciPy's mahalanobis() ‚Äî requires two 1D vectors + inverse covariance\n",
    "    M = distance.mahalanobis(mean_t, mean_c, inv_cov)\n",
    "    return M\n",
    "\n",
    "# --------------------------\n",
    "# Step 2: Rerandomization loop\n",
    "# --------------------------\n",
    "def rerandomize_df(df, covariate_cols, threshold=0.3, max_iter=10000):\n",
    "    n = len(df)\n",
    "    for _ in range(max_iter):\n",
    "        df[\"treatment\"] = np.random.choice([0, 1], size=n)\n",
    "        df_treat = df[df[\"treatment\"] == 1]\n",
    "        df_ctrl = df[df[\"treatment\"] == 0]\n",
    "        \n",
    "        M = mahalanobis_distance(df_treat, df_ctrl, covariate_cols)\n",
    "        \n",
    "        if M < threshold:\n",
    "            return df.copy(), M\n",
    "    raise RuntimeError(\"Failed to find balanced randomization\")\n",
    "\n",
    "# --------------------------\n",
    "# Step 3: Simulate cluster data\n",
    "# --------------------------\n",
    "np.random.seed(42)\n",
    "df = pd.DataFrame({\n",
    "    \"cluster_id\": range(100),\n",
    "    \"cluster_size\": np.random.randint(50, 100, size=100),\n",
    "    \"baseline_rate\": np.random.uniform(0.05, 0.15, size=100),\n",
    "    \"region\": np.random.choice([\"NA\", \"EU\", \"APAC\"], size=100)\n",
    "})\n",
    "\n",
    "# Convert categorical variable 'region' to numeric dummies\n",
    "df = pd.get_dummies(df, columns=[\"region\"], drop_first=True)\n",
    "\n",
    "# --------------------------\n",
    "# Step 4: Run rerandomization\n",
    "# --------------------------\n",
    "covariates = [\"cluster_size\", \"baseline_rate\", \"region_EU\", \"region_NA\"]\n",
    "\n",
    "balanced_df, M_final = rerandomize_df(df, covariates, threshold=0.3)\n",
    "print(f\"Accepted assignment with Mahalanobis distance: {M_final:.4f}\")\n",
    "\n",
    "# --------------------------\n",
    "# Step 5: Check covariate balance\n",
    "# --------------------------\n",
    "summary = balanced_df.groupby(\"treatment\")[covariates].mean().T\n",
    "summary[\"abs_diff\"] = abs(summary[0] - summary[1])\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1cf723",
   "metadata": {},
   "source": [
    " ## üîπ 6. Cluster Randomization \n",
    "\n",
    "Instead of randomizing individuals, you randomize entire clusters (groups of users).\n",
    "- Example: In a social network, you don‚Äôt want friends in different arms because of interference. So you randomize at the cluster (friend group) level.- - Another example: Randomize whole schools into ‚Äúnew curriculum‚Äù vs ‚Äúold curriculum.‚Äù\n",
    "\n",
    "Steps:\n",
    "1.\tIdentify clusters (e.g., schools, groups).\n",
    "2.\tRandomly assign whole clusters to treatment/control.\n",
    "3.\tAll individuals in a cluster follow the cluster‚Äôs assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc449343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    student_id  cluster_id assignment\n",
      "0            1           1  Treatment\n",
      "1            2           1  Treatment\n",
      "2            3           1  Treatment\n",
      "3            4           1  Treatment\n",
      "4            5           1  Treatment\n",
      "5            6           2  Treatment\n",
      "6            7           2  Treatment\n",
      "7            8           2  Treatment\n",
      "8            9           2  Treatment\n",
      "9           10           2  Treatment\n",
      "10          11           3    Control\n",
      "11          12           3    Control\n",
      "12          13           3    Control\n",
      "13          14           3    Control\n",
      "14          15           3    Control\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Suppose we have 10 clusters (schools), each with multiple students\n",
    "np.random.seed(42)\n",
    "students = pd.DataFrame({\n",
    "    \"student_id\": np.arange(1, 51),\n",
    "    \"cluster_id\": np.repeat(np.arange(1, 11), 5)  # 10 clusters, 5 students each\n",
    "})\n",
    "\n",
    "# Randomly assign clusters to treatment/control\n",
    "clusters = students[\"cluster_id\"].unique()\n",
    "treatment_clusters = np.random.choice(clusters, size=len(clusters)//2, replace=False)\n",
    "\n",
    "# Mark assignment at cluster level\n",
    "students[\"assignment\"] = students[\"cluster_id\"].apply(\n",
    "    lambda c: \"Treatment\" if c in treatment_clusters else \"Control\"\n",
    ")\n",
    "\n",
    "print(students.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4c8dc9",
   "metadata": {},
   "source": [
    "## Stratified Block Randomization\n",
    "\n",
    "This combines:\n",
    "- Stratification: ensures balance across important covariates (e.g., gender, age group).\n",
    "- Blocking: ensures balance within small blocks.\n",
    "\n",
    "This is especially common in clinical trials where you want guaranteed balance across multiple dimensions.\n",
    "\n",
    "Example:\n",
    "- Suppose we want equal Treatment/Control assignment within each gender group.\n",
    "- Within each stratum (Male/Female), we also randomize in blocks of size 4 to keep things balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2acbaed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id  gender assignment\n",
      "0    1    Male    Control\n",
      "1    2  Female    Control\n",
      "2    3    Male    Control\n",
      "3    4    Male    Control\n",
      "4    5    Male  Treatment\n",
      "5    6    Male    Control\n",
      "6    7    Male  Treatment\n",
      "7    8  Female    Control\n",
      "8    9  Female  Treatment\n",
      "9   10    Male  Treatment\n",
      "10  11  Female  Treatment\n",
      "11  12  Female  Treatment\n",
      "12  13    Male    Control\n",
      "13  14  Female    Control\n",
      "14  15    Male    Control\n",
      "15  16  Female  Treatment\n",
      "16  17    Male  Treatment\n",
      "17  18  Female    Control\n",
      "18  19  Female    Control\n",
      "19  20    Male  Treatment\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(123)\n",
    "# Simulated participants\n",
    "participants = pd.DataFrame({\n",
    "    \"id\": np.arange(1, 21),\n",
    "    \"gender\": np.random.choice([\"Male\", \"Female\"], size=20)\n",
    "})\n",
    "\n",
    "def stratified_block_randomization(df, stratify_col, block_size=4):\n",
    "    assignments = []\n",
    "    for stratum, group in df.groupby(stratify_col):\n",
    "        group_ids = group[\"id\"].tolist()\n",
    "        np.random.shuffle(group_ids)\n",
    "        \n",
    "        # Break into blocks\n",
    "        for i in range(0, len(group_ids), block_size):\n",
    "            block = group_ids[i:i+block_size]\n",
    "            # Assign half to treatment, half to control\n",
    "            half = len(block) // 2\n",
    "            assignments.extend([(pid, \"Treatment\") for pid in block[:half]])\n",
    "            assignments.extend([(pid, \"Control\") for pid in block[half:]])\n",
    "    \n",
    "    return pd.DataFrame(assignments, columns=[\"id\", \"assignment\"])\n",
    "\n",
    "assignments = stratified_block_randomization(participants, \"gender\", block_size=4)\n",
    "participants = participants.merge(assignments, on=\"id\")\n",
    "\n",
    "print(participants.sort_values(\"id\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbae6c0",
   "metadata": {},
   "source": [
    "## 7. üéØ Matched-Pair Randomization\n",
    "\n",
    "This is often the final step up in sophistication after stratified randomization ‚Äî and yes, Meta and similar companies use it frequently in clustered or small-sample experiments.\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "üß† Intuition\n",
    "- You pair units (or clusters) that are very similar across covariates.\n",
    "- Then, randomly assign one unit from each pair to treatment and the other to control.\n",
    "- This ensures tight covariate balance, even with small samples or heterogeneous clusters.\n",
    "\n",
    "It‚Äôs like a ‚Äú1-to-1‚Äù stratification, but using similarity across multiple features instead of a single categorical stratum.\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "‚öôÔ∏è When it‚Äôs used\n",
    "- When you have a small number of clusters (e.g., schools, cities, regions).\n",
    "- When each cluster has rich metadata (e.g., population, revenue, baseline activity rate).\n",
    "- When covariate balance is critical.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a2457e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, np.int64(12)), (1, np.int64(17)), (2, np.int64(18)), (3, np.int64(13)), (4, np.int64(6)), (7, np.int64(10))]\n",
      "group                   control  treatment  abs_diff\n",
      "size                 142.666667  137.50000  5.166667\n",
      "baseline_engagement    0.228145    0.22406  0.004085\n",
      "region_code            1.000000    1.00000  0.000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "# Step 1: Simulate cluster data\n",
    "np.random.seed(42)\n",
    "df = pd.DataFrame({\n",
    "    \"cluster_id\": range(1, 21),\n",
    "    \"size\": np.random.randint(50, 200, 20),\n",
    "    \"baseline_engagement\": np.random.uniform(0.1, 0.5, 20),\n",
    "    \"region_code\": np.random.choice([0, 1, 2], 20)  # NA, EU, APAC (encoded)\n",
    "})\n",
    "\n",
    "# Step 2: Normalize covariates for distance computation\n",
    "covariates = [\"size\", \"baseline_engagement\", \"region_code\"]\n",
    "X = (df[covariates] - df[covariates].mean()) / df[covariates].std()\n",
    "\n",
    "# Step 3: Compute pairwise distances and find nearest pairs\n",
    "dist_matrix = pairwise_distances(X)\n",
    "np.fill_diagonal(dist_matrix, np.inf)\n",
    "\n",
    "pairs = []\n",
    "unpaired = set(df.index)\n",
    "\n",
    "while unpaired:\n",
    "    i = unpaired.pop()\n",
    "    j = np.argmin(dist_matrix[i])\n",
    "    if j in unpaired:\n",
    "        unpaired.remove(j)\n",
    "        pairs.append((i, j))\n",
    "print(pairs)\n",
    "\n",
    "# Step 4: Randomly assign one in each pair to treatment, one to control\n",
    "assignments = {}\n",
    "for i, j in pairs:\n",
    "    if np.random.rand() < 0.5:\n",
    "        assignments[i], assignments[j] = \"treatment\", \"control\"\n",
    "    else:\n",
    "        assignments[i], assignments[j] = \"control\", \"treatment\"\n",
    "\n",
    "df[\"group\"] = df.index.map(assignments)\n",
    "\n",
    "# Step 5: Check balance\n",
    "summary = df.groupby(\"group\")[covariates].mean().T\n",
    "summary[\"abs_diff\"] = abs(summary[\"treatment\"] - summary[\"control\"])\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a63ca56",
   "metadata": {},
   "source": [
    "## Social Media effect and handling of network effects through network clustering\n",
    "1Ô∏è‚É£ What is network interference?\n",
    "- Standard A/B tests assume the Stable Unit Treatment Value Assumption (SUTVA):\n",
    "The outcome of one user is independent of the treatment assignment of other users.\n",
    "- Network interference breaks this assumption:\n",
    "- A user‚Äôs reaction can be influenced by friends, followers, or peers who are in treatment or control.\n",
    "- Example: A new ‚Äúreaction button‚Äù might spread via social influence, not just individual exposure.\n",
    "\n",
    "Consequences:\n",
    "- Standard randomization estimates can be biased.\n",
    "- Treatment effect estimates ignore spillover effects, leading to over- or underestimation.\n",
    "\n",
    "\n",
    "\n",
    "2Ô∏è‚É£ Key approaches to handle network interference\n",
    "\n",
    "A. Cluster / Group Randomization\n",
    "- Randomize at the group / network cluster level instead of individual users.\n",
    "- Example: Randomize entire social circles or communities.\n",
    "- Pros: Reduces cross-treatment contamination.\n",
    "- Cons: Fewer clusters ‚Üí lower statistical power.\n",
    "\n",
    "B. Exposure modeling\n",
    "- Model each user‚Äôs effective treatment as a combination of:\n",
    "- Their own treatment\n",
    "- Fraction of treated neighbors\n",
    "- Creates continuous treatment intensity (0‚Äì1).\n",
    "- Analysis requires regression or mixed models.\n",
    "\n",
    "Conceptual formula:\n",
    "$$\n",
    "Y_i = \\beta_0 + \\beta_1 T_i + \\beta_2 \\frac{\\text{number of treated neighbors}}{\\text{number of neighbors}} + \\epsilon_i\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "C. Graph-based randomization\n",
    "- Use the network graph structure to assign treatment:\n",
    "- Maximize separation between treated and control neighbors.\n",
    "- Avoid direct neighbors being in different groups.\n",
    "- Techniques:\n",
    "- Graph coloring or community detection.\n",
    "- Assign entire detected communities to treatment or control.\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "D. Randomized saturation design\n",
    "- Randomize treatment probability within clusters, not absolute treatment.\n",
    "- Example:\n",
    "- Cluster A: 70% treated, 30% control\n",
    "- Cluster B: 30% treated, 70% control\n",
    "- Allows estimation of spillover effects using different exposure levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0714ff3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 50 nodes and 120 edges\n",
      "Naive treatment effect (individual randomization): 0.203\n",
      "Estimated treatment effect (cluster randomization): 0.189\n",
      "\n",
      "Number of treated vs control users\n",
      "treatment_cluster\n",
      "0    27\n",
      "1    23\n",
      "Name: user_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from scipy import stats\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# --------------------------\n",
    "# Step 1: Create a network\n",
    "# --------------------------\n",
    "n_users = 50\n",
    "\n",
    "# Create a random graph (Erdos-Renyi)\n",
    "p_edge = 0.1  # probability of connection\n",
    "G = nx.erdos_renyi_graph(n_users, p_edge, seed=42)\n",
    "print(G)\n",
    "# Convert to dataframe for easier handling\n",
    "df = pd.DataFrame({\n",
    "    \"user_id\": list(G.nodes),\n",
    "})\n",
    "\n",
    "# Compute neighbors for each user\n",
    "df['neighbors'] = df['user_id'].apply(lambda u: list(G.neighbors(u)))\n",
    "df['n_neighbors'] = df['neighbors'].apply(len)\n",
    "\n",
    "# --------------------------\n",
    "# Step 2: Individual randomization\n",
    "# --------------------------\n",
    "df['treatment_individual'] = np.random.choice([0,1], size=n_users)\n",
    "\n",
    "# Define outcome with spillover: \n",
    "# Base rate + 0.2 * own treatment + 0.1 * fraction of treated neighbors + noise\n",
    "def compute_outcome(row, treatment_col='treatment_individual'):\n",
    "    frac_treated_neighbors = np.mean([df.loc[n, treatment_col] for n in row['neighbors']]) if row['n_neighbors'] > 0 else 0\n",
    "    return 0.05 + 0.2*row[treatment_col] + 0.1*frac_treated_neighbors + np.random.normal(0,0.01)\n",
    "\n",
    "df['outcome_individual'] = df.apply(compute_outcome, axis=1)\n",
    "\n",
    "# Estimate naive treatment effect (ignores spillover)\n",
    "treat_mean = df[df['treatment_individual']==1]['outcome_individual'].mean()\n",
    "control_mean = df[df['treatment_individual']==0]['outcome_individual'].mean()\n",
    "naive_effect = treat_mean - control_mean\n",
    "print(f\"Naive treatment effect (individual randomization): {naive_effect:.3f}\")\n",
    "\n",
    "# --------------------------\n",
    "# Step 3: Cluster randomization\n",
    "# --------------------------\n",
    "# Assign users into 5 clusters (randomly)\n",
    "n_clusters = 5\n",
    "cluster_ids = np.random.choice(range(n_clusters), size=n_users)\n",
    "df['cluster_id'] = cluster_ids\n",
    "\n",
    "# Randomize treatment at cluster level\n",
    "treat_clusters = np.random.choice(range(n_clusters), size=n_clusters//2, replace=False)\n",
    "df['treatment_cluster'] = df['cluster_id'].apply(lambda c: 1 if c in treat_clusters else 0)\n",
    "\n",
    "# Compute outcome again using spillover\n",
    "df['outcome_cluster'] = df.apply(lambda row: compute_outcome(row, treatment_col='treatment_cluster'), axis=1)\n",
    "\n",
    "# Estimate effect using cluster-level treatment\n",
    "treat_mean_cl = df[df['treatment_cluster']==1]['outcome_cluster'].mean()\n",
    "control_mean_cl = df[df['treatment_cluster']==0]['outcome_cluster'].mean()\n",
    "cluster_effect = treat_mean_cl - control_mean_cl\n",
    "print(f\"Estimated treatment effect (cluster randomization): {cluster_effect:.3f}\")\n",
    "\n",
    "# --------------------------\n",
    "# Step 4: Observations\n",
    "# --------------------------\n",
    "print(\"\\nNumber of treated vs control users\")\n",
    "print(df.groupby('treatment_cluster')['user_id'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811b1c68",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc678da",
   "metadata": {},
   "source": [
    "## üîπ 1. Simple Randomization (Coin Flip)\n",
    "\n",
    "- Each unit (user/cluster) is independently randomized.\n",
    "    * May result in imbalance (e.g., 7 treatment, 3 control).\n",
    "\t* Fine when large samples are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05f6b4f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_size = 10\n",
    "labels = np.random.choice([0, 1], size=sample_size)\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d3ed81",
   "metadata": {},
   "source": [
    "## üîπ 2. Complete Randomization (Fixed Split)\n",
    "\n",
    "- Ensure exact balance between groups.\n",
    "- Guarantees equal treatment/control sizes (5 and 5 here).\n",
    "- Common in A/B tests to avoid imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61a37200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_size = 10\n",
    "half = sample_size // 2\n",
    "\n",
    "labels = np.array([0 , 1])\n",
    "np.random.shuffle(labels)\n",
    "\n",
    "assignments = np.array([labels[0]]* half + [labels[1]]* (sample_size - half))\n",
    "np.random.shuffle(assignments)\n",
    "assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ae4e74",
   "metadata": {},
   "source": [
    "## üîπ 3. Blocked Randomization\n",
    "\n",
    "Randomize within small blocks to maintain balance over time or within subgroups.\n",
    "- Every 4 clusters ‚Üí 2 control, 2 treatment.\n",
    "- Prevents imbalance if experiment stops early.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cae526f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(1),\n",
       " np.int64(1),\n",
       " np.int64(1),\n",
       " np.int64(1),\n",
       " np.int64(1)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_size = 100\n",
    "block_size = 10\n",
    "labels = np.array([0,1])\n",
    "half = block_size // 2\n",
    "assignments = []\n",
    "for _ in range(sample_size // block_size):\n",
    "    np.random.shuffle(labels)\n",
    "    block = np.array([labels[0]] * half + [labels[1]] * (block_size - half))\n",
    "    np.random.shuffle(block)\n",
    "    assignments.extend(block)\n",
    "assignments[0:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc81a327",
   "metadata": {},
   "source": [
    "## üîπ 4. Stratified Randomization\n",
    "\n",
    "First divide clusters into strata (based on covariates), then randomize within each stratum.\n",
    "\n",
    "Example: Stratify clusters into ‚Äúsmall‚Äù vs ‚Äúlarge‚Äù based on size.\n",
    "- Ensures treatment/control are balanced within strata.\n",
    "- Useful if cluster size (or baseline metric) strongly influences outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "157e960e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "18\n",
      "[np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>size</th>\n",
       "      <th>stratum</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>large</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>large</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>small</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>92</td>\n",
       "      <td>large</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>small</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>70</td>\n",
       "      <td>small</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>88</td>\n",
       "      <td>large</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>68</td>\n",
       "      <td>small</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>72</td>\n",
       "      <td>small</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "      <td>small</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>small</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>73</td>\n",
       "      <td>small</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>85</td>\n",
       "      <td>large</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>89</td>\n",
       "      <td>large</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>73</td>\n",
       "      <td>small</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>52</td>\n",
       "      <td>small</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>71</td>\n",
       "      <td>small</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>51</td>\n",
       "      <td>small</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>73</td>\n",
       "      <td>small</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>93</td>\n",
       "      <td>large</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>79</td>\n",
       "      <td>large</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>87</td>\n",
       "      <td>large</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>51</td>\n",
       "      <td>small</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>70</td>\n",
       "      <td>small</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>82</td>\n",
       "      <td>large</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>61</td>\n",
       "      <td>small</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>71</td>\n",
       "      <td>small</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>93</td>\n",
       "      <td>large</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>74</td>\n",
       "      <td>small</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>98</td>\n",
       "      <td>large</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cluster  size stratum  group\n",
       "0         0    88   large      1\n",
       "1         1    78   large      0\n",
       "2         2    64   small      0\n",
       "3         3    92   large      1\n",
       "4         4    57   small      1\n",
       "5         5    70   small      0\n",
       "6         6    88   large      1\n",
       "7         7    68   small      1\n",
       "8         8    72   small      0\n",
       "9         9    60   small      1\n",
       "10       10    60   small      0\n",
       "11       11    73   small      0\n",
       "12       12    85   large      1\n",
       "13       13    89   large      0\n",
       "14       14    73   small      0\n",
       "15       15    52   small      0\n",
       "16       16    71   small      0\n",
       "17       17    51   small      1\n",
       "18       18    73   small      1\n",
       "19       19    93   large      1\n",
       "20       20    79   large      0\n",
       "21       21    87   large      1\n",
       "22       22    51   small      1\n",
       "23       23    70   small      1\n",
       "24       24    82   large      0\n",
       "25       25    61   small      1\n",
       "26       26    71   small      1\n",
       "27       27    93   large      0\n",
       "28       28    74   small      0\n",
       "29       29    98   large      0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "num_clusters = 30\n",
    "cluster_sizes = np.random.randint(50, 100,  size=num_clusters)\n",
    "df = pd.DataFrame({\"cluster\":range(num_clusters),\n",
    "                   \"size\": cluster_sizes\n",
    "                   })\n",
    "df[\"stratum\"] = np.where(df['size'] > 75, \"large\", \"small\" )\n",
    "grp_labels = [0, 1]\n",
    "assigments = []\n",
    "for startum, group in df.groupby(\"stratum\"):\n",
    "    np.random.shuffle(grp_labels)\n",
    "    grp_size = len(group)\n",
    "    print(grp_size)\n",
    "    half = grp_size // 2\n",
    "    labels = np.array([grp_labels[0]] * half + [grp_labels[1]] * (grp_size - half) )\n",
    "    np.random.shuffle(labels)\n",
    "    assigments.extend(labels)\n",
    "print(assigments)\n",
    "df[\"group\"] = assigments\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d895b6",
   "metadata": {},
   "source": [
    "### üéØ What stratified randomization means\n",
    "\n",
    "Stratified randomization ensures balance within key subgroups (strata).\n",
    "You divide your population into homogeneous groups (strata) based on an important feature ‚Äî then randomize within each stratum.\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "üß† Two ways to form strata\n",
    "1.\tDerived strata (like cluster size)\n",
    "- You compute a stratum variable (e.g., cluster_size > median ‚Üí \"large\" else \"small\").\n",
    "- Used when you don‚Äôt already have a clear categorical variable.\n",
    "2.\tExisting strata (like age, gender, region)\n",
    "- You use an existing feature directly.\n",
    "- For instance, if your dataset has an age column, you can stratify by it:\n",
    "- Continuous ‚Üí convert into bins (e.g., 18‚Äì25, 26‚Äì40, 41‚Äì60, 60+).\n",
    "- Categorical ‚Üí use as-is (e.g., region, gender)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41ff7519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group      control  treatment\n",
      "age_group                    \n",
      "18-25           41         40\n",
      "26-40           59         59\n",
      "41-60          105        104\n",
      "60+             46         46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pw/ct2l9dz532s3m_xxwd5ngrth0000gn/T/ipykernel_15427/1408407988.py:18: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for stratum, group_data in df.groupby(\"age_group\"):\n",
      "/var/folders/pw/ct2l9dz532s3m_xxwd5ngrth0000gn/T/ipykernel_15427/1408407988.py:24: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  print(df.groupby([\"age_group\", \"group\"]).size().unstack())\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Simulated data\n",
    "np.random.seed(42)\n",
    "df = pd.DataFrame({\n",
    "    \"user_id\": range(1, 501),\n",
    "    \"age\": np.random.randint(18, 70, 500),\n",
    "    \"region\": np.random.choice([\"NA\", \"EU\", \"APAC\"], size=500)\n",
    "})\n",
    "\n",
    "# Step 1: Create age strata (existing feature -> binned)\n",
    "df[\"age_group\"] = pd.cut(df[\"age\"], bins=[17, 25, 40, 60, 100],\n",
    "                         labels=[\"18-25\", \"26-40\", \"41-60\", \"60+\"])\n",
    "\n",
    "# Step 2: Stratified randomization\n",
    "df[\"group\"] = None\n",
    "for stratum, group_data in df.groupby(\"age_group\"):\n",
    "    treated = np.random.choice(group_data.index, size=len(group_data)//2, replace=False)\n",
    "    df.loc[group_data.index, \"group\"] = \"control\"\n",
    "    df.loc[treated, \"group\"] = \"treatment\"\n",
    "\n",
    "# Step 3: Verify balance by stratum\n",
    "print(df.groupby([\"age_group\", \"group\"]).size().unstack())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "128ccc50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"group\"] == 0 ].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6dcd4e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"group\"] == 1 ].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b1a717e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'stratum'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Shubham/datascience/study/statistics/HypothesisTesting/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'stratum'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m (df[(df[\u001b[33m\"\u001b[39m\u001b[33mgroup\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[32m0\u001b[39m) & (\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstratum\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m == \u001b[33m'\u001b[39m\u001b[33msmall\u001b[39m\u001b[33m'\u001b[39m)].size)/(df[(df[\u001b[33m\"\u001b[39m\u001b[33mgroup\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[32m0\u001b[39m) & (df[\u001b[33m'\u001b[39m\u001b[33mstratum\u001b[39m\u001b[33m'\u001b[39m] == \u001b[33m'\u001b[39m\u001b[33mlarge\u001b[39m\u001b[33m'\u001b[39m)].size) \n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Shubham/datascience/study/statistics/HypothesisTesting/.venv/lib/python3.11/site-packages/pandas/core/frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Shubham/datascience/study/statistics/HypothesisTesting/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'stratum'"
     ]
    }
   ],
   "source": [
    "(df[(df[\"group\"] == 0) & (df['stratum'] == 'small')].size)/(df[(df[\"group\"] == 0) & (df['stratum'] == 'large')].size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064384ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df[df['stratum'] == 'small'].size) / df[df['stratum'] == 'large'].size "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41837d2",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "## üîπ 5. Re-Randomization / Constrained Randomization\n",
    "\n",
    "Randomize, then check balance on covariates. If imbalance is too high, randomize again.\n",
    "- Guarantees covariate balance.\n",
    "- Used in constrained randomization designs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55a2fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[94 83 96 89 72 73 78 87 63 88 97 98 67 98 82 88 66 86 60 79 55 69 76 73\n",
      " 72 94 55 64 99 79 60 61 96 88 80 61 55 78 79 96 56 66 57 57 52 94 79 94\n",
      " 99 69 51 59 59 90 70 85 73 51 52 51 82 81 78 56 76 64 97 96 74 65 91 55\n",
      " 92 82 63 67 78 50 59 72 51 79 58 65 88 96 72 77 76 66 99 59 62 68 91 89\n",
      " 51 90 60 85]\n",
      "[1 1 1 0 1 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 1\n",
      " 1 1 0 1 1 1 1 0 0 0 0 1 1 0 1 0 1 1 0 1 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0\n",
      " 1 1 0 0 1 1 0 1 0 1 0 0 0 1 0 0 1 1 1 0 1 1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "n_clusters = 100\n",
    "cluster_sizes = np.random.randint(50, 100, size = n_clusters)\n",
    "threshold = 3\n",
    "\n",
    "while True:\n",
    "    assignments = np.random.choice([0, 1], size=n_clusters)\n",
    "    label_1_mean = cluster_sizes[assignments == 1].mean()\n",
    "    label_0_mean = cluster_sizes[assignments == 0].mean()\n",
    "    if abs(label_1_mean -label_0_mean) <= threshold:\n",
    "        break;\n",
    "        \n",
    "\n",
    "print(cluster_sizes)\n",
    "print(assignments)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6821c6b5",
   "metadata": {},
   "source": [
    "### Multi-variate re-randomization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d2140c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##-------TO-DO--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cbfd63",
   "metadata": {},
   "source": [
    " ## üîπ 6. Cluster Randomization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c283aa2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10  1  8 12  5 11 13 20  3  7]\n",
      "    student_id  cluster_id      group\n",
      "0            1           1  treatment\n",
      "1            2           1  treatment\n",
      "2            3           1  treatment\n",
      "3            4           1  treatment\n",
      "4            5           1  treatment\n",
      "..         ...         ...        ...\n",
      "95          96           4    control\n",
      "96          97           4    control\n",
      "97          98           4    control\n",
      "98          99           4    control\n",
      "99         100           4    control\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_cluster = 20\n",
    "sample_size = 500\n",
    "df = pd.DataFrame({\n",
    "        \"student_id\": np.arange(1, sample_size + 1),\n",
    "        \"cluster_id\": np.repeat(np.arange(1, n_cluster + 1) , sample_size // n_cluster)\n",
    "})\n",
    "cluster_ids = df['cluster_id'].unique()\n",
    "treatment_clusters = np.random.choice(cluster_ids, size=len(cluster_ids)//2, replace=False)\n",
    "print(treatment_clusters)\n",
    "df['group'] = df.cluster_id.apply(lambda c: \"treatment\" if c in treatment_clusters else \"control\")\n",
    "print(df.head(100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9518ebe6",
   "metadata": {},
   "source": [
    "## Social Media effect and handling of network effects through net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3afeb4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first create a network\n",
    "n_users = 500\n",
    "p_connection = 0.1\n",
    "\n",
    "network = nx.erdos_renyi_graph(n=n_users, p=p_connection, seed=42)\n",
    "\n",
    "# save the graph information in a dataframe\n",
    "df = pd.DataFrame({\n",
    "                    \"user_ids\": list(network.nodes)\n",
    "                    })\n",
    "df[\"neighbours\"] = df['user_ids'].apply(lambda n: list(network.neighbors(n)))\n",
    "df[\"n_neighbours\"] = df['neighbours'].apply(len)\n",
    "\n",
    "# assign treatment and control at the user level\n",
    "df['individual_treatment'] = np.random.choice([0,1], n_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332b6f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "subset_nodes = list(range(30))\n",
    "subgraph = network.subgraph(subset_nodes)\n",
    "pos = nx.spring_layout(subgraph, seed=42)  # spring layout = visually appealing placement\n",
    "nx.draw(\n",
    "    subgraph,\n",
    "    pos,\n",
    "    with_labels=True,\n",
    "    node_color=\"skyblue\",\n",
    "    node_size=600,\n",
    "    edge_color=\"gray\",\n",
    "    font_size=9,\n",
    ")\n",
    "plt.title(\"Erd≈ës‚ÄìR√©nyi Random Graph (n=30, p=0.1)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "41f37af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the outcome of the spill over effect using\n",
    "# outcome = Base rate + independent_treatment_effect_rate * own treatment + neighbor_treatment_effect_rate * fraction of treated neighbors + noise\n",
    "# Assume:  base rate = 0.05, independent_treatment_effect_rate= 0.2, neighbor_treatment_effect_rate = 0.1\n",
    "\n",
    "def compute_outcome(df, row, treatment_col):\n",
    "    frac_treated_neighbors = np.mean([df.loc[n, treatment_col] for n in row['neighbours']]) if row['n_neighbours'] > 0 else 0\n",
    "    return 0.05 + 0.2 * row[treatment_col] + 0.1 * frac_treated_neighbors + np.random.normal(0, 0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "678ac73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive randomization mean difference: 0.20106006823711992\n"
     ]
    }
   ],
   "source": [
    "df['outcome_individual'] = df.apply(lambda row: compute_outcome(df, row, treatment_col='individual_treatment'), axis=1)\n",
    "# Calculate the difference in means of the treatment and control groups\n",
    "treat_ind_mean = np.mean(df[df['individual_treatment'] == 1]['outcome_individual'])\n",
    "ctrl_ind_mean = np.mean(df[df['individual_treatment'] == 0]['outcome_individual'])\n",
    "naive_randomization_effect = treat_ind_mean - ctrl_ind_mean\n",
    "print(f\"Naive randomization mean difference: {naive_randomization_effect}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f62d3c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets do random cluster asssigments\n",
    "n_clusters = 10\n",
    "cluster_ids = np.random.choice(range(1, n_clusters), size=n_users)\n",
    "np.random.shuffle(cluster_ids)\n",
    "df['cluster_ids'] = cluster_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fe22f57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_clusters = np.random.choice(range(1,n_clusters), size=n_clusters//2)\n",
    "df['cluster_treatment'] = df['cluster_ids'].apply(lambda c_id: 1 if c_id in treatment_clusters else 0)\n",
    "df['cluster_outcome'] = df.apply(lambda row: compute_outcome(df=df, row=row, treatment_col='cluster_treatment'), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0f35bf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive randomization mean difference: 0.20106006823711992\n",
      "Cluster randomization mean difference: 0.19823547269830577\n"
     ]
    }
   ],
   "source": [
    "treat_clust_mean = np.mean(df[df['cluster_treatment'] == 1]['cluster_outcome'])\n",
    "ctrl_clust_mean = np.mean(df[df['cluster_treatment'] == 0]['cluster_outcome'])\n",
    "cluster_randomization_effect = treat_clust_mean - ctrl_clust_mean\n",
    "print(f\"Naive randomization mean difference: {naive_randomization_effect}\")\n",
    "print(f\"Cluster randomization mean difference: {cluster_randomization_effect}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97dc2e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
